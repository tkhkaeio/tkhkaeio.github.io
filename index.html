<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Take Ohkawa</title>
  
  <meta name="author" content="Take Ohkawa - UTokyo">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="NBt3cmFe-oTUP8zdL5-eVck05i7BoTOek46Cv9eIGmY">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="XXX"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Take Ohkawa</name>
              </p>
              <p>
                Hi, I am <b>Take Ohkawa (大川 武彦)</b>.<br> I am a first-year Ph.D. student (2021-) at Graduate School of Information Science and Technology, The University of Tokyo, advised by Prof. <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.hci.iis.u-tokyo.ac.jp%2F~ysato%2Findex.html&sa=D&sntz=1&usg=AFQjCNGn61xbd_93U17-55A7PwtdupV_jw">Yoichi Sato</a>.<br>

                Currently, I am a Research Scholar in the laboratory of Prof. <a href="http://www.cs.cmu.edu/~kkitani/">Kris Kitani</a> at Carnegie Mellon University, and I am also working with Dr. <a href="http://yoshitakaushiku.net/">Yoshitaka Ushiku</a> and Dr. <a href="https://atsushihashimoto.github.io/cv/#profile">Atsushi Hashimoto</a> at <a href="https://www.omron.com/sinicx/">OMRON SINIC X</a> and Prof. <a href="http://www.lsta.media.kyoto-u.ac.jp/home-e.html">Shinsuke Mori</a> at Kyoto University.
            　</p>
            <p>
                I am the youngest Principal Investigator of <a href="https://www.jst.go.jp/kisoken/act-x/en/project/111F001/111F001_2020.html">JST ACT-X Project on "Human Behavior Understanding via Imitative AI Agents"</a> (2020-2023).<br>
            </p>
            <p>
                I received my master's degree for 1.5-year early graduation at The University of Tokyo under the supervision of Prof. <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.hci.iis.u-tokyo.ac.jp%2F~ysato%2Findex.html&sa=D&sntz=1&usg=AFQjCNGn61xbd_93U17-55A7PwtdupV_jw">Yoichi Sato</a> and Prof. <a href="https://lab.rekimoto.org/members/rekimoto/">Jun Rekimoto</a>. Before that, I received my bachelor's for three-year early graduation at the Tokyo Institute of Technology under the supervision of Prof. <a href="https://www.google.com/url?q=https%3A%2F%2Fmmai.tech%2F%23home&sa=D&sntz=1&usg=AFQjCNHFzzL1iApg76zsB8hBWNS-fGyrtg">Nakamasa Inoue</a>.
                <br> Prior to the bachelor's laboratory assignment, I voluntarily conducted various research projects with Prof. <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.ks.c.titech.ac.jp%2F~shinoda%2Findex.html&sa=D&sntz=1&usg=AFQjCNHYXCsAe_UkdMMRg7SxTCzSsS7-Cg">Koichi Shinoda</a>                            (Speech), Prof. <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.ymatsuo.com%2F&sa=D&sntz=1&usg=AFQjCNGTFtL0e4HnNWViMbXcqxkygBoz5g">Yutaka Matsuo</a> (AI), Prof. <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.chokkan.org%2Findex.en.html&sa=D&sntz=1&usg=AFQjCNERO4X90fx_xrtsQEGLiczXnaWopA">Naoaki Okazaki</a>                            (NLP), and Prof. <a href="http://www.google.com/url?q=http%3A%2F%2Fwww.cbi.c.titech.ac.jp%2Fsekijima.html&sa=D&sntz=1&usg=AFQjCNFSCKmGj9FkReAzjJiWYN2qzV5NIA">Masakazu Sekijima</a> (BioInfo).
                <br>
              </p>
              <p style="text-align:left">
                E-mail: ohkawa-t [at] iis.u-tokyo.ac.jp<br>
                <!-- <a href="mailto:xxx@x.com">Email</a> &nbsp/&nbsp -->
                <a href="assets/CV_2021_11.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="xxx.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?hl=en&user=WX3cmSsAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/tkhkaeio">Twitter</a>
                <!-- &nbsp/&nbsp -->
                <!-- <a href="https://github.com/xxxx/">Github</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="https://user-images.githubusercontent.com/28190044/93294887-c2de0f80-f826-11ea-910a-8c7523e9db88.png"><img style="width:100%;max-width:100%" alt="profile photo" src="https://user-images.githubusercontent.com/28190044/93294887-c2de0f80-f826-11ea-910a-8c7523e9db88.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
                <p>
                    <b>[Sep 2021]</b> Joined <a href="http://www.cs.cmu.edu/~kkitani/">Kris Lab</a>, CMU as a Research Scholar.<br>
                    <b>[Sep 2021]</b> Obtained M.A.S. for 1.5 years (<font color="red"><b>Early Graduation</b></font>) at UTokyo.<br>
                    <b>[Jun 2021]</b> One paper <a href="http://arxiv.org/abs/2107.02718" border="0">"Domain Adaptation of Hand Segmentation"</a> was accepted to IEEE Access 2021.<br>
                    <b>[Oct 2020]</b> My research proposal was accepted to <a href="https://www.jst.go.jp/kisoken/act-x/en/project/111F001/111F001_2020.html">JST ACT-X</a>.<br>
                    <b>[Oct 2020]</b> One paper <a href="https://arxiv.org/abs/2003.00187" border="0">"Augmented Cyclic Consistency Regularization"</a> was accepted to ICPR2020.<br>
                    <b>[Aug 2020]</b> Started an internship at <a href="https://www.omron.com/sinicx/">OSX</a>.<br>
                    <!-- <b>[Jun 2020]</b> Prof. <a href="https://lab.rekimoto.org/members/rekimoto/">Jun Rekimoto</a> became my co-advisor.<br> -->
                    <b>[Apr 2020]</b> Joined <a href="https://www.ut-vision.org/sato-lab/">Sato/Sugano Lab</a>, UTokyo.<br>
                    <b>[Mar 2020]</b> Obtained B.E. for three years (<font color="red"><b>Early Graduation</b></font>) at TokyoTech.<br>
                    <b>[Oct 2019]</b> Gifted NVIDIA RTX 2080Ti from <a href="https://twitter.com/tkhkaeio/status/1186167767415672833?s=20">Yu Darvish</a>, a Japanese MLB player who I respect the most!<br>
                    <b>[Oct 2019]</b> Joined <a href="https://www.google.com/url?q=https%3A%2F%2Fmmai.tech%2F%23home&sa=D&sntz=1&usg=AFQjCNHFzzL1iApg76zsB8hBWNS-fGyrtg">Inoue Lab</a>, TokyoTech.<br>
                </p>
    
            </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                <blockquote style="font-style: italic;">
                    <p>"It is not the strongest of the species that survives, nor the most intelligent. It is the one most <b>adaptable to change</b>." <div style="text-align: right">-Charles Darwin (1809-1882)</div></p>
                </blockquote>
                C. Darwin left us with an astute analysis of how intelligence could function in the wild. The quote above represents the findings of his lifelong research.<br>
                
                <br>
                In my quest for robust, flexible, and reliable machine intelligence, I am engaging in <b>computer vision</b> and <b>machine learning</b> research. 
                My research objective is to <b>build a real-world visual perception system for understanding human behavior in diverse domains and applications</b>. I focus on extending in-the-wild perception systems for comprehension of daily human activities to diverse deployment scenarios while alleviating dataset bias, such as environment changes, viewpoint shifts, and the differences in an agent's embodiment, e.g., between humans and robots.
                To achieve this, I am working on <b>transfer learning under distribution shift</b> and <b>human behavior understanding in videos</b>, specializing in domain adaptation, generative modeling, first-person/embodied vision, and vision-and-language.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
          <!-- <tr onmouseout="idName_stop()" onmouseover="idName_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='id_name'><video  width=100% height=100% muted autoplay loop>
                <source src="images/xxx.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='https://user-images.githubusercontent.com/28190044/106457189-f2d63880-64d1-11eb-9cfa-cc22e79b7809.png' width="160">
              </div>
              <script type="text/javascript">
                function idName_start() {
                  document.getElementById('id_name').style.opacity = "1";
                }
                function idName_stop() {
                  document.getElementById('id_name').style.opacity = "0";
                }
                idName_stop()
              </script>
            </td> -->
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <img src="https://user-images.githubusercontent.com/28190044/124936861-dcfd0e80-e041-11eb-98bb-64ae613aa74c.gif" width="180" height="180">
                    <!-- <img src="https://user-images.githubusercontent.com/28190044/123925072-851d3280-d9c5-11eb-907e-70dd17d0225d.jpg" width="180"> -->
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://arxiv.org/abs/2107.02718">
                <papertitle>Foreground-Aware Stylization and Consensus Pseudo-Labeling for Domain Adaptation of First-Person Hand Segmentation</papertitle><br>
              </a>
              <b>Takehiko Ohkawa</b>, Takuma Yagi, Atsushi Hashimoto, Yoshitaka Ushiku, and Yoichi Sato<br>
              <em><b>IEEE Access</b></em>, 2021<br>
              <a href="http://arxiv.org/abs/2107.02718">[Paper]</a>
              <a href="https://ieeexplore.ieee.org/document/9469781">[IEEE Xplore]</a>
              <!-- <a href="https://www.youtube.com/watch?v=xxxx">video</a> -->
              <a href="projects/21_FgSty-CPL/">[Project]</a>
              <a href="https://github.com/ut-vision/FgSty-CPL"> [Data & Code]</a>

              <p>
                  We developed a domain adaptation method for hand segmentation in first-person videos, consisting of foreground-aware stylization and consensus pseudo-labeling.
              </p>
            </td>
            </tbody>
            <tbody>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <img src="https://user-images.githubusercontent.com/28190044/106457189-f2d63880-64d1-11eb-9cfa-cc22e79b7809.png" width="180" height="180">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2003.00187">
                <papertitle>Augmented Cyclic Consistency Regularization for Unpaired Image-to-Image Translation</papertitle>
              </a>
              <br>
              <b>Takehiko Ohkawa</b>, Naoto Inoue, Hirokatsu Kataoka, and Nakamasa Inoue
              <br>
              <em>International Conference on Pattern Recognition (<b>ICPR</b>)</em>, 2020  
              <br>
              <!-- <a href="xxxxx">project page</a> / -->
              <a href="https://arxiv.org/abs/2003.00187">[Paper]</a>
              <a href="./projects/20_ACCR/accr2020.txt">[BibTex]</a>
              <!-- <a href="https://www.youtube.com/watch?v=xxxx">video</a> -->
              <p></p>
              <p>
                  We developed extended consistency regularization for stabilizing the training of image-to-image translation models using real, fake, and reconstructed samples.
              </p>
            </td></tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <subheading>Short Papers (in domestic conferences)</subheading>
              <p>
                <papertitle>Foreground-Aware Stylization and Consensus Pseudo-Labeling for Domain Adaptation of First-Person Hand Segmentation</papertitle><br>
                <b>Takehiko Ohkawa</b>, Takuma Yagi, Atsushi Hashimoto, Yoshitaka Ushiku, and Yoichi Sato<br>
                <em>Meeting on Image Recognition and Understanding (<b>MIRU</b>)</em>, 2021, Japan (<b>Long oral</b>).<br>
                <font color="red"><b>MIRU Student Encouragement Award</b></font>
                <br>
                <br>
                <papertitle>Style Adapted DataBase: Generalizing Hand Segmentation via Semantics-aware Stylization</papertitle> <br>
                <b>Takehiko Ohkawa</b>, Takuma Yagi, and Yoichi Sato<br>
                <em>IEICE Technical Report (<b>PRMU</b>)</em>, 2020, Japan.<br>
                <font color="red"><b>PRMU Best Presentation of the Month</b></font>
                <br>
                <br>
                <papertitle>Consistency Regularization using Data Augmentation for Cycle-Consistent GANs</papertitle><br>
                <b>Takehiko Ohkawa</b>, Naoto Inoue, Hirokatsu Kataoka, and Nakamasa Inoue<br>
                <em>Meeting on Image Recognition and Understanding (<b>MIRU</b>)</em>, 2020, Japan.
                <br>
                <br>
                <papertitle>Stabilizing Object-aware Representation Learning with Cyclic Annealing on KL Regularization</papertitle> <br>
                Hideki Tsunashima, <b>Takehiko Ohkawa</b>, Hiroaki Aizawa, Hirokatsu Kataoka, and Shigeo Morishima<br>
                <em>Meeting on Image Recognition and Understanding (<b>MIRU</b>)</em>, 2020, Japan.
                <br>
              </p>
            </td></tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research & Work Experience</heading>
              <p>
                <b>[Sep 2021 - Present]</b> Research scholar, <a href="http://www.cs.cmu.edu/~kkitani/">Kris Lab</a>, Carnegie Mellon University<br>  
                <b>[Nov 2020 - Present]</b> Research assistant, <a href="https://www.ut-vision.org/sato-lab/">Sato Lab</a>, The University of Tokyo<br>
                <b>[Feb 2019 - Present]</b> Student researcher, <a href="http://xpaperchallenge.org/cv/">cvpaper.challenge</a>, <a href="https://www.google.com/url?q=https%3A%2F%2Fwww.aist.go.jp%2Findex_en.html&sa=D&sntz=1&usg=AFQjCNHcFF2d0S_ymFehZa5cee7xxsDzww">AIST</a> <br>
                <b>[Aug 2020 - Aug 2021]</b> Research internship, <a href="https://www.omron.com/sinicx/">OMRON SINIC X Corp.</a><br>
                <b>[Oct 2019 - May 2020]</b> Research internship, <a href="https://www.google.com/url?q=https%3A%2F%2Fwww.neuralpocket.com%2Fen%2F&sa=D&sntz=1&usg=AFQjCNHPYi2Zyj7HCozNbgGoqOxrXLViow">Neural Pocket Inc.</a><br>
                <b>[Aug 2019 - Mar 2020]</b> Research assistant, <a href="https://www.google.com/url?q=https%3A%2F%2Fmmai.tech%2F%23home&sa=D&sntz=1&usg=AFQjCNHFzzL1iApg76zsB8hBWNS-fGyrtg">Inoue Lab</a>, Tokyo Institute of Technology<br>
                <b>[Aug 2019 - Sep 2019]</b> Engineering internship, <a href="https://www.google.com/url?q=https%3A%2F%2Fwww.teamlab.art%2F&sa=D&sntz=1&usg=AFQjCNGtI-cRUBi2GvUXaa0A-WPIxxyA6w">teamLab Inc.</a> <br>
                <b>[Dec 2017 - Nov 2018]</b> Research internship, <a href="https://www.google.com/url?q=https%3A%2F%2Fwww.cross-compass.com%2Fen%2Ffront-page%2F&sa=D&sntz=1&usg=AFQjCNHBhiK40Hg3ganunGUZLZIzIrUoXg"> Cross Compass Ltd. </a>
              </p>
            </td>
            </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards & Grants</heading>
              <p>
                JSPS Research Fellowship for Young Scientists (DC1), 2022-2025 (expected)<br>
                ACT-X "Frontier of Mathematics and Information Science", Japan Science and Technology Agency, 2020-2023 (expected)<br>
                MIRU Student Encouragement Award, 2021<br>
                PRMU Best Presentation of the Month, 2020<br>
                JEES/Softbank AI Scholarship, 2020<br>
                Tokio Marine Kagami Memorial Foundation Scholarship, 2018-2020<br>
              </p>
            </td>
            </tr>
        </tbody></table>
                
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
            <br>
              <p style="text-align:right;font-size:small;">
                © Takehiko Ohkawa 2021 /
                Design: <a href="https://github.com/jonbarron/jonbarron_website">jonbarron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
        <script>
            (function(i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r;
                i[r] = i[r] || function() {
                    (i[r].q = i[r].q || []).push(arguments)
                }, i[r].l = 1 * new Date();
                a = s.createElement(o),
                    m = s.getElementsByTagName(o)[0];
                a.async = 1;
                a.src = g;
                m.parentNode.insertBefore(a, m)
            })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

            ga('create', 'UA-162031573-1', 'auto');
            ga('send', 'pageview');
        </script>
      </td>
    </tr>
  </tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe>
  <div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div>
</body>

</html>
